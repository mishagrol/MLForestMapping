{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e535d2c",
   "metadata": {},
   "source": [
    "# 1. Forest Classification and Model Selection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore forest classification using ensemble methods and metric models. We will also perform model selection to identify the best-performing model based on various evaluation metrics.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Data Preparation**: Load and preprocess the dataset.\n",
    "2. **Model Training**: Train Random Forest and Extra Trees classifiers.\n",
    "3. **Model Evaluation**: Evaluate the performance of each model using metrics such as accuracy, precision, recall, and F1-score.\n",
    "4. **Hyperparameter Tuning**: Use techniques like Grid Search and Random Search to optimize model parameters.\n",
    "5. **Model Selection**: Compare the models and select the best one based on evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89263973-344c-460d-a588-cce007e6f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip3 -q install yellowbrick\n",
    "# !pip3 -q install imblearn\n",
    "# !pip3 -q install scienceplots\n",
    "# !pip3 -q install xgboost\n",
    "# !pip3 -q install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859a92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2102996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "#clustering\n",
    "from shapely import affinity\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#test/train split and hyperparameters optimisation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "#ML\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, cohen_kappa_score \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "\n",
    "#xgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#stats\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dict_normal_names={7: \"Pine\", \n",
    "        5:\"Aspen\",\n",
    "        4: \"Larch\", \n",
    "        1:\"Birch\",\n",
    "        6:\"Silver fir\",\n",
    "        15:\"Burnt forest\", \n",
    "        13:'Deforestation', \n",
    "        14:'Grass',\n",
    "        12:'Soil', \n",
    "        16:'Swamp', \n",
    "        11:'Water body',\n",
    "        17:'Settlements'}\n",
    "\n",
    "colors =[\n",
    "    '#117733',\n",
    "    '#50CE57',\n",
    "    '#23A28F',\n",
    "    '#5BD0AE',\n",
    "    '#88CCEE', \n",
    "    '#92462D', \n",
    "    '#DE7486',\n",
    "    '#DDCC77',\n",
    "    '#AA4499',\n",
    "    '#0f62fe',\n",
    "    '#be95ff'\n",
    "]\n",
    "\n",
    "#model saving\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb0e8d",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08403f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_models():\n",
    "    return { \n",
    "        \"kNN\": KNeighborsClassifier(n_jobs=6), \n",
    "        \"SVC\": SVC(probability=True), # to speed up LinearSVC\n",
    "        \"RandomForest\": RandomForestClassifier(bootstrap=True, n_jobs=6), \n",
    "        \"XGB\": xgb.XGBClassifier(n_jobs=6)}\n",
    "\n",
    "\n",
    "def get_predictions(data,\n",
    "                    model,\n",
    "                    param_grid,\n",
    "                    target_column: str = 'class',\n",
    "                    stratify_column: str = 'key',\n",
    "                    to_remove_columns: list = ['key'],\n",
    "                    test_size: float=0.3,\n",
    "                    smote_balance: bool=True,\n",
    "                    cv: int=5,\n",
    "                    n_iter_search: int=15,\n",
    "                    label_encoder: bool=False,\n",
    "                   verbose: int = 0,):\n",
    "    #test/train spliting considering key overlap problems and missed classes\n",
    "    n = 0\n",
    "    while True:\n",
    "        train_inds, test_inds = next(\n",
    "            GroupShuffleSplit(\n",
    "                test_size=test_size, n_splits=2  # ,random_state = 40\n",
    "            ).split(data, groups=data[stratify_column])\n",
    "        )\n",
    "        # because we need pixels from same plots to be separated in train and test\n",
    "        train = data.iloc[train_inds]\n",
    "        test = data.iloc[test_inds]\n",
    "\n",
    "        train_classes = train[target_column].nunique()\n",
    "        test_classes = test[target_column].nunique()\n",
    "        all_classes = data[target_column].nunique()\n",
    "        # because we need classes to be represented in train and test\n",
    "        n+=1\n",
    "        if train_classes == test_classes == all_classes:\n",
    "            break\n",
    "        if n>40:\n",
    "            print(f'N - {n}')\n",
    "            msg= f'Train - {train_classes}, Test = {test_classes}, All - {all_classes}'\n",
    "            print(msg)\n",
    "            raise KeyError('Problems in train/test split')\n",
    "        \n",
    "    train = train.drop(columns=to_remove_columns)\n",
    "    test = test.drop(columns=to_remove_columns)\n",
    "    #class balansing with smote\n",
    "    if smote_balance is True:\n",
    "        smote = SMOTE(random_state = 42)\n",
    "        X, y = smote.fit_resample(train.loc[:, train.columns!=target_column],\n",
    "                                  train[target_column]) #drops 3 columns: key, class, and forest\n",
    "        df_smote = pd.DataFrame(X, columns = train.loc[:, train.columns!=target_column].columns.tolist()) #drops 3 columns: key, class, and forest\n",
    "\n",
    "        #we set train/test from SMOTE results\n",
    "        X_train = df_smote\n",
    "        y_train = y\n",
    "        X_test = test.loc[:, train.columns!=target_column]\n",
    "        y_test = test[target_column]\n",
    "        #we set train/test as it is\n",
    "    else:\n",
    "        X_train = train.loc[:, train.columns!=target_column]\n",
    "        y_train = train[target_column]\n",
    "        X_test = test.loc[:, train.columns!=target_column]\n",
    "        y_test = test[target_column]\n",
    "    model = init_models()[model]\n",
    "    gs = RandomizedSearchCV(estimator=model,\n",
    "                            param_distributions = param_grid,\n",
    "                            n_iter = n_iter_search,\n",
    "                            cv = cv,\n",
    "                            scoring= 'f1_weighted', \n",
    "                            verbose=verbose,\n",
    "                           n_jobs = N_JOBS_CV)\n",
    "\n",
    "    if label_encoder == True:\n",
    "        le = LabelEncoder()\n",
    "        gs.fit(X_train, le.fit_transform(y_train))\n",
    "        y_pred = gs.best_estimator_.predict(X_test)\n",
    "        model_fit = gs.best_estimator_\n",
    "        y_proba = gs.best_estimator_.predict_proba(X_test)\n",
    "        # model_name = gs.best_estimator_.__class__.__name__\n",
    "        # pd.concat([X_test, y_test, y_pred, y_proba], axis=1).to_csv(f'{model_name}_for_conformal.csv')\n",
    "        results = {'model': model_fit,\n",
    "            'X_train data': X_train,\n",
    "            'y train data': y_train,\n",
    "            'X test data': X_test,\n",
    "            'y test data': y_test,\n",
    "            'y predicted': le.inverse_transform(y_pred),\n",
    "            'y proba': y_proba\n",
    "            }\n",
    "\n",
    "    else:\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.best_estimator_.predict(X_test)\n",
    "        model_fit = gs.best_estimator_\n",
    "        y_proba = gs.best_estimator_.predict_proba(X_test)\n",
    "        # model_name = gs.best_estimator_.__class__.__name__\n",
    "        # pd.concat([X_test, y_test, y_pred, y_proba], axis=1).to_csv(f'{model_name}_for_conformal.csv')\n",
    "\n",
    "        results = {'model': model_fit,\n",
    "                   'X_train data': X_train,\n",
    "                   'y train data':  y_train,\n",
    "                   'X test data': X_test,\n",
    "                   'y test data': y_test,\n",
    "                   'y predicted': y_pred,\n",
    "                   'y proba': y_proba\n",
    "\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561af040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_description(y_true, y_pred, \n",
    "                        metrics_by_class: bool=True, \n",
    "                        confusion_matrix_multiclass_on: bool=True,\n",
    "                        binary_matrix_on: bool=False):\n",
    "\n",
    "    \n",
    "    print('Accuracy score: %.2f%%' %(accuracy_score(y_true, y_pred)*100))  \n",
    "    print('Precision score: %.2f%%' % (precision_score(y_true, y_pred, average= 'weighted')*100))\n",
    "    print('Recall score: %.2f%%' % (recall_score(y_true, y_pred, average= 'weighted')*100))\n",
    "    print('F1-Score: %.2f%%'%(f1_score(y_true, y_pred, average = 'weighted')*100))\n",
    "    print('Kappa score: %.2f%%'%(cohen_kappa_score(y_true, y_pred)*100))\n",
    "    \n",
    "    \n",
    "    #dataframe with metrics by class\n",
    "    if metrics_by_class is True:\n",
    "        metrics_by_class = pd.DataFrame(\n",
    "                {\n",
    "                    'names': list(map(dict_normal_names.get, list(np.unique(y_true)))),\n",
    "                    'f1_scores': f1_score(y_true, y_pred,\n",
    "                               average=None).round(2).tolist(),\n",
    "                    'precision': precision_score(y_true, y_pred, \n",
    "                                       average=None).round(2).tolist(),\n",
    "                    'recall':recall_score(y_true, y_pred,\n",
    "                                       average=None).round(2).tolist()\n",
    "                }\n",
    "            )\n",
    "        display(metrics_by_class)\n",
    "\n",
    "    #confusion matrix multiclass\n",
    "    if confusion_matrix_multiclass_on is True:\n",
    "        data = confusion_matrix(y_true, y_pred)\n",
    "        df_cm = pd.DataFrame(data, columns=list(map(dict_normal_names.get, list(np.unique(y_true)))), \n",
    "                             index = list(map(dict_normal_names.get, list(np.unique(y_true)))))\n",
    "        df_cm.index.name = 'Actual'\n",
    "        df_cm.columns.name = 'Predicted'\n",
    "\n",
    "        #confusion matrix plot\n",
    "        f, ax = plt.subplots(figsize=(6, 10))\n",
    "        cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "        sns.heatmap(df_cm, cbar=False, annot=True, cmap=cmap, square=True, fmt='.0f',\n",
    "                    annot_kws={'size': 10})\n",
    "        plt.title('Actuals vs Predicted')\n",
    "        plt.show()\n",
    "        \n",
    "    #confusion matrix binary    \n",
    "    if binary_matrix_on is True:\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print('Confusion matrix\\n\\n', cm)\n",
    "        ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fbb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dataset with metrics by class for each random prediction\n",
    "def get_classes_metrics(models_vector): #vector with model variations, y predicted and y true from the dataset\n",
    "    class_metrics_dataframe = pd.DataFrame()\n",
    "    count = 0 #counter of iteration\n",
    "\n",
    "    for i in models_vector:\n",
    "\n",
    "        count += 1 #counting\n",
    "        pred = i['y predicted'] #predicted values \n",
    "        true = i['y test data'] #corresponding labels from random test set\n",
    "        names_list = list(np.unique(true))\n",
    "\n",
    "        temp = pd.DataFrame(\n",
    "            {\n",
    "                'iteration':[count]*len(names_list), \n",
    "                'names': list(map(dict_normal_names.get, names_list)),\n",
    "                'f1_scores': f1_score(true, pred,\n",
    "                           average=None).round(2).tolist(),\n",
    "                'precision_list': precision_score(true, \n",
    "                                   pred, \n",
    "                                   average=None).round(2).tolist(),\n",
    "                'recall':recall_score(true, \n",
    "                                   pred, \n",
    "                                   average=None).round(2).tolist()\n",
    "            }\n",
    "        ) #dataset for each model \n",
    "\n",
    "        class_metrics_dataframe = pd.concat([class_metrics_dataframe, temp], ignore_index=True)\n",
    "    return class_metrics_dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e923ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_average(models_vector): #vector with model variations, y predicted and y true from the dataset\n",
    "    average_metrics_dataframe = pd.DataFrame()\n",
    "    count = 0 #counter of iteration\n",
    "\n",
    "    for i in models_vector:\n",
    "\n",
    "        count += 1 #counting\n",
    "        pred = i['y predicted'] #predicted values \n",
    "        true = i['y test data'] #corresponding labels from random test set\n",
    "\n",
    "        temp = pd.DataFrame(\n",
    "            {\n",
    "                'iteration':[count],#*len(names_list), \n",
    "                #'names': list(map(dict_normal_names.get, names_list)),\n",
    "                'f1_scores': f1_score(true, pred,\n",
    "                           average='weighted').round(2).tolist(),\n",
    "                'precision_list': precision_score(true, \n",
    "                                   pred, \n",
    "                                   average='weighted').round(2).tolist(),\n",
    "                'recall':recall_score(true, \n",
    "                                   pred, \n",
    "                                   average='weighted').round(2).tolist()\n",
    "            }\n",
    "        ) #dataset for each model \n",
    "\n",
    "        average_metrics_dataframe = pd.concat([average_metrics_dataframe, temp], \n",
    "                                              ignore_index=True)\n",
    "    return average_metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44e926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(datavector_models):\n",
    "    number = get_metrics_average(datavector_models).sort_values(by='f1_scores', \n",
    "                                                                ascending=False).head(1).reset_index()['index'].values[0]\n",
    "    best_model = datavector_models[number]['model']\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2dfe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_model(datavector_models):\n",
    "    number = get_metrics_average(datavector_models).sort_values(by='f1_scores', \n",
    "                                                                ascending=False).tail(1).reset_index()['index'].values[0]\n",
    "    best_model = datavector_models[number]['model']\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d9a42",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1a38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_data(path:str, cols_remove:list=['key', 'class']):\n",
    "    df = pd.read_csv(path)\n",
    "    mask = df['class']!=2\n",
    "    df=df.loc[mask]\n",
    "    x = df.drop(columns=cols_remove).values\n",
    "    #minmax scaling\n",
    "    min_max_scaler = preprocessing.MinMaxScaler() \n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    target_cols = [col for col in list(df.columns) if col not in cols_remove]\n",
    "    df.loc[:, target_cols] = x_scaled\n",
    "    return df, min_max_scaler\n",
    "folder = '../shape_data/filtered_datasets_2024/'\n",
    "df_scaled, min_max_scaler = get_scaled_data(os.path.join(folder, 'df3_notfiltered.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76851acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest():\n",
    "    n_estimators = np.arange(100,200,20)\n",
    "    max_depth = np.arange(10,110,11)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}\n",
    "    return {\"grid\":random_grid}\n",
    "\n",
    "def get_svm():\n",
    "    svc_grid = {'C': [0.01, 0.1, 10,100], \n",
    "              # 'gamma': [1, 0.1, 0.01],\n",
    "              # 'kernel': ['rbf', 'linear', 'poly']\n",
    "             }\n",
    "    return {\"grid\":svc_grid}\n",
    "def get_KNN():\n",
    "    metric = ['euclidean','manhattan','chebyshev','minkowski']\n",
    "    n_neighbors = np.arange(4,15,2)\n",
    "    weights = ['uniform','distance']\n",
    "    random_grid_knn = {'n_neighbors': n_neighbors,\n",
    "        'weights': weights,\n",
    "        'metric': metric}\n",
    "    return {\"grid\":random_grid_knn}\n",
    "\n",
    "def get_XGB():\n",
    "    params = { 'max_depth': [3,6,10],\n",
    "           \"min_child_weight\": [0.5, 1, 2],\n",
    "           'n_estimators': np.arange(10,80,20),\n",
    "           'colsample_bytree': [0.3, 0.7, 1]}\n",
    "    return {\"grid\":params}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852eab5f",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "645d0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loop(df_forest: pd.DataFrame, model: str,  param_grid: dict, smote_balance: bool, verbose: int = 0):\n",
    "    datavector = []\n",
    "    for i in range(15):\n",
    "        print(f\"{model} ---- {i}\")\n",
    "        trained_model = get_predictions(data = df_forest,\n",
    "                    model = model,\n",
    "                    param_grid = param_grid,\n",
    "                    target_column = 'class',\n",
    "                    to_remove_columns=['key'],\n",
    "                    smote_balance=smote_balance,\n",
    "                    cv=5, \n",
    "                    n_iter_search=20, \n",
    "                    label_encoder=True if model == 'XGB' else False, \n",
    "                    verbose=verbose)\n",
    "        datavector.append(trained_model)\n",
    "    return datavector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfac46b2-0826-4d09-92cd-89691bb7cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_computed_metrics(metrics: pd.DataFrame, dataset: str, model: str):\n",
    "    if 'fname' not in metrics:\n",
    "        return False\n",
    "    mask = (metrics['fname']==dataset) & (metrics['model']==model) \n",
    "    if len(metrics.loc[mask])==150:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a06fd9a6-3395-4578-968b-19e8a7a8bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fname = '../shape_data/metric_results_v7.csv'\n",
    "metric_stats_fname = '../shape_data/metric_stats_v7.csv'\n",
    "if os.path.isfile(metric_fname):\n",
    "    print('Use cached metrics')\n",
    "    metric_container = pd.read_csv(metric_fname, index_col=0)\n",
    "    metric_stats_container = pd.read_csv(metric_stats_fname, index_col=0)\n",
    "else:\n",
    "    metric_container = pd.DataFrame()\n",
    "    metric_stats_container = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b928e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1_filtered_modified.csv\n",
      "RandomForest 1 SMOTE True\n",
      "RandomForest ---- 0\n",
      "RandomForest ---- 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m smote_balance \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]:            \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model,scale, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMOTE\u001b[39m\u001b[38;5;124m'\u001b[39m, smote_balance)\n\u001b[0;32m---> 28\u001b[0m     datavector \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_forest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msmote_balance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Metrics related to forest types\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     model_metrics \u001b[38;5;241m=\u001b[39m get_classes_metrics(datavector)\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mmodel_loop\u001b[0;34m(df_forest, model, param_grid, smote_balance, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_forest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mto_remove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43msmote_balance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmote_balance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_iter_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     datavector\u001b[38;5;241m.\u001b[39mappend(trained_model)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datavector\n",
      "Cell \u001b[0;32mIn[68], line 92\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(data, model, param_grid, target_column, stratify_column, to_remove_columns, test_size, smote_balance, cv, n_iter_search, label_encoder, verbose)\u001b[0m\n\u001b[1;32m     83\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_fit,\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train data\u001b[39m\u001b[38;5;124m'\u001b[39m: X_train,\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my train data\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my predicted\u001b[39m\u001b[38;5;124m'\u001b[39m: le\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n\u001b[1;32m     89\u001b[0m         }\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     94\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/geo/lib/python3.12/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder = '../shape_data/filtered_datasets_2024/'\n",
    "datasets = os.listdir(folder)\n",
    "problems = []\n",
    "\n",
    "for dataset in sorted(datasets):\n",
    "    print(dataset)\n",
    "    scale = dataset[2]\n",
    "    df_scaled, min_max_scaler = get_scaled_data(os.path.join(folder, dataset))    \n",
    "    mask_forest = df_scaled['class']<10\n",
    "    df_forest = df_scaled.loc[mask_forest]\n",
    "    models = {\n",
    "            'RandomForest': get_random_forest(), \n",
    "             \"SVC\":get_svm(),\n",
    "            \"kNN\":get_KNN(),\n",
    "            \"XGB\":get_XGB()\n",
    "             }\n",
    "    for model, param_grid in models.items():\n",
    "        if model=='SVC':\n",
    "            N_JOBS_CV = 4\n",
    "        else:\n",
    "            N_JOBS_CV = 1\n",
    "        status_computed = check_computed_metrics(metric_container,dataset,model)\n",
    "        if status_computed==True:\n",
    "            print(f'Computed prev metrics for: {dataset} & {model}')\n",
    "            continue\n",
    "        for smote_balance in [True, False]:            \n",
    "            print(model,scale, 'SMOTE', smote_balance)\n",
    "            datavector = model_loop(df_forest, \n",
    "                                    model, \n",
    "                                    param_grid['grid'], \n",
    "                                    smote_balance, \n",
    "                                    verbose = 0)\n",
    "            \n",
    "            \n",
    "    \n",
    "            \n",
    "            # Metrics related to forest types\n",
    "\n",
    "            model_metrics = get_classes_metrics(datavector)\n",
    "            model_metrics['model'] = model\n",
    "            model_metrics['smote_balance'] = smote_balance\n",
    "            model_metrics['scale'] = scale\n",
    "            model_metrics['fname'] = dataset\n",
    "            model_metrics['experiment_status'] = 'Done'\n",
    "            metric_container = pd.concat([metric_container, model_metrics], axis=0)\n",
    "\n",
    "            # Metrics related to forest\n",
    "            metricts_stats = get_metrics_average(datavector)\n",
    "            metricts_stats['model'] = model\n",
    "            metricts_stats['smote_balance'] = smote_balance\n",
    "            metricts_stats['scale'] = scale\n",
    "            metricts_stats['fname'] = dataset\n",
    "            metricts_stats['experiment_status'] = 'Done'\n",
    "            metric_stats_container = pd.concat([metric_stats_container, metricts_stats], axis=0)\n",
    "            \n",
    "            best_model = get_best_model(datavector)\n",
    "            core = dataset.split('.')[0]\n",
    "            model_path = os.path.join(f'../models/best_models/{model}_{core}.joblib')\n",
    "            dump(best_model, model_path)\n",
    "        metric_container.to_csv('../shape_data/metric_results_v7.csv')\n",
    "        metric_stats_container.to_csv('../shape_data/metric_stats_v7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72203efb",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c0428",
   "metadata": {},
   "source": [
    "Conformal prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96bf7016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df3_notfiltered.csv\n",
      "RandomForest 3 SMOTE False\n",
      "RandomForest ---- 0\n",
      "SVC 3 SMOTE False\n",
      "SVC ---- 0\n",
      "kNN 3 SMOTE False\n",
      "kNN ---- 0\n",
      "XGB 3 SMOTE False\n",
      "XGB ---- 0\n"
     ]
    }
   ],
   "source": [
    "folder = '../shape_data/filtered_datasets_2024/'\n",
    "datasets = os.listdir(folder)\n",
    "problems = []\n",
    "dataset = 'df3_notfiltered.csv'\n",
    "smote_balance = False\n",
    "\n",
    "print(dataset)\n",
    "scale = dataset[2]\n",
    "df_scaled, min_max_scaler = get_scaled_data(os.path.join(folder, dataset))    \n",
    "mask_forest = df_scaled['class']<10\n",
    "df_forest = df_scaled.loc[mask_forest]\n",
    "models = {\n",
    "        'RandomForest': get_random_forest(), \n",
    "            \"SVC\":get_svm(),\n",
    "        \"kNN\":get_KNN(),\n",
    "        \"XGB\":get_XGB()\n",
    "            }\n",
    "for model, param_grid in models.items():\n",
    "    if model=='SVC':\n",
    "        N_JOBS_CV = 4\n",
    "    else:\n",
    "        N_JOBS_CV = 1\n",
    "    # status_computed = check_computed_metrics(metric_container,dataset,model)\n",
    "    # if status_computed==True:\n",
    "    #     print(f'Computed prev metrics for: {dataset} & {model}')\n",
    "    #     continue\n",
    "    # for smote_balance in [True, False]:            \n",
    "    print(model,scale, 'SMOTE', smote_balance)\n",
    "    verbose = 0\n",
    "    datavector = []\n",
    "    for i in range(1):\n",
    "        print(f\"{model} ---- {i}\")\n",
    "        trained_model = get_predictions(data = df_forest,\n",
    "                    model = model,\n",
    "                    param_grid = param_grid['grid'],\n",
    "                    target_column = 'class',\n",
    "                    to_remove_columns=['key'],\n",
    "                    smote_balance=smote_balance,\n",
    "                    cv=5, \n",
    "                    n_iter_search=20, \n",
    "                    label_encoder=True if model == 'XGB' else False, \n",
    "                    verbose=verbose)\n",
    "        datavector.append(trained_model)\n",
    "    # datavector = model_loop(df_forest, \n",
    "    #                         model, \n",
    "    #                         param_grid['grid'], \n",
    "    #                         smote_balance, \n",
    "    #                         verbose = 0)\n",
    "    \n",
    "    \n",
    "    col_names = [f'class_prob_{name}' for name in trained_model['model'].classes_]\n",
    "    probs_df=pd.DataFrame(trained_model['y proba'], columns=col_names)\n",
    "    probs_df['observed_class']=trained_model['y test data'].reset_index(drop=True)\n",
    "    probs_df['predicted_class']=trained_model['y predicted']\n",
    "    all_df= pd.concat([trained_model['X test data'].reset_index(drop=True), probs_df], axis=1)\n",
    "\n",
    "    all_df.to_csv(f'conformal_predictions_{model}_{core}.csv', index=False)\n",
    "    \n",
    "    # Metrics related to forest types\n",
    "\n",
    "    # model_metrics = get_classes_metrics(datavector)\n",
    "    # model_metrics['model'] = model\n",
    "    # model_metrics['smote_balance'] = smote_balance\n",
    "    # model_metrics['scale'] = scale\n",
    "    # model_metrics['fname'] = dataset\n",
    "    # model_metrics['experiment_status'] = 'Done'\n",
    "    # metric_container = pd.concat([metric_container, model_metrics], axis=0)\n",
    "\n",
    "    # # Metrics related to forest\n",
    "    # metricts_stats = get_metrics_average(datavector)\n",
    "    # metricts_stats['model'] = model\n",
    "    # metricts_stats['smote_balance'] = smote_balance\n",
    "    # metricts_stats['scale'] = scale\n",
    "    # metricts_stats['fname'] = dataset\n",
    "    # metricts_stats['experiment_status'] = 'Done'\n",
    "    # metric_stats_container = pd.concat([metric_stats_container, metricts_stats], axis=0)\n",
    "    \n",
    "    best_model = get_best_model(datavector)\n",
    "    core = dataset.split('.')[0]\n",
    "    model_path = os.path.join(f'../models/{model}_{core}.joblib')\n",
    "    dump(best_model, model_path)\n",
    "    # break\n",
    "    # metric_container.to_csv('../shape_data/metric_results_v7.csv')\n",
    "    # metric_stats_container.to_csv('../shape_data/metric_stats_v7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baef6ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B09</th>\n",
       "      <th>...</th>\n",
       "      <th>energy2</th>\n",
       "      <th>homogeneity1</th>\n",
       "      <th>homogeneity2</th>\n",
       "      <th>class_prob_1</th>\n",
       "      <th>class_prob_4</th>\n",
       "      <th>class_prob_5</th>\n",
       "      <th>class_prob_6</th>\n",
       "      <th>class_prob_7</th>\n",
       "      <th>observed_class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202290</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.102996</td>\n",
       "      <td>0.073466</td>\n",
       "      <td>0.286765</td>\n",
       "      <td>0.771346</td>\n",
       "      <td>0.962482</td>\n",
       "      <td>0.921642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218782</td>\n",
       "      <td>0.402796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178435</td>\n",
       "      <td>0.063435</td>\n",
       "      <td>0.108614</td>\n",
       "      <td>0.072385</td>\n",
       "      <td>0.287059</td>\n",
       "      <td>0.783846</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217343</td>\n",
       "      <td>0.383868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202290</td>\n",
       "      <td>0.073749</td>\n",
       "      <td>0.104401</td>\n",
       "      <td>0.077787</td>\n",
       "      <td>0.288235</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.955087</td>\n",
       "      <td>0.836176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222542</td>\n",
       "      <td>0.437208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202290</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.109082</td>\n",
       "      <td>0.074546</td>\n",
       "      <td>0.288235</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.955087</td>\n",
       "      <td>0.927861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221511</td>\n",
       "      <td>0.413216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178435</td>\n",
       "      <td>0.062919</td>\n",
       "      <td>0.106742</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.295294</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219992</td>\n",
       "      <td>0.391755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.072202</td>\n",
       "      <td>0.104401</td>\n",
       "      <td>0.104149</td>\n",
       "      <td>0.321176</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.979076</td>\n",
       "      <td>0.961976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.409244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.060340</td>\n",
       "      <td>0.101592</td>\n",
       "      <td>0.103717</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.806538</td>\n",
       "      <td>0.975469</td>\n",
       "      <td>0.944208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268392</td>\n",
       "      <td>0.426828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.705556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0.117978</td>\n",
       "      <td>0.105445</td>\n",
       "      <td>0.335882</td>\n",
       "      <td>0.812692</td>\n",
       "      <td>0.981602</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263709</td>\n",
       "      <td>0.393910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.111891</td>\n",
       "      <td>0.104149</td>\n",
       "      <td>0.330588</td>\n",
       "      <td>0.812692</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.948827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267171</td>\n",
       "      <td>0.388909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>0.110019</td>\n",
       "      <td>0.105877</td>\n",
       "      <td>0.327059</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.926439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270371</td>\n",
       "      <td>0.399323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1423 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           B01       B02       B03       B04       B05       B06       B07  \\\n",
       "0     0.202290  0.069881  0.102996  0.073466  0.286765  0.771346  0.962482   \n",
       "1     0.178435  0.063435  0.108614  0.072385  0.287059  0.783846  0.989899   \n",
       "2     0.202290  0.073749  0.104401  0.077787  0.288235  0.771154  0.955087   \n",
       "3     0.202290  0.071429  0.109082  0.074546  0.288235  0.771154  0.955087   \n",
       "4     0.178435  0.062919  0.106742  0.071737  0.295294  0.843462  1.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1418  0.259542  0.072202  0.104401  0.104149  0.321176  0.806923  0.979076   \n",
       "1419  0.259542  0.060340  0.101592  0.103717  0.320000  0.806538  0.975469   \n",
       "1420  0.259542  0.061372  0.117978  0.105445  0.335882  0.812692  0.981602   \n",
       "1421  0.259542  0.063950  0.111891  0.104149  0.330588  0.812692  0.977273   \n",
       "1422  0.259542  0.075297  0.110019  0.105877  0.327059  0.806923  0.977273   \n",
       "\n",
       "           B08  B8A       B09  ...   energy2  homogeneity1  homogeneity2  \\\n",
       "0     0.921642  1.0  0.780807  ...  0.218782      0.402796           1.0   \n",
       "1     0.968195  1.0  0.767176  ...  0.217343      0.383868           1.0   \n",
       "2     0.836176  1.0  0.780807  ...  0.222542      0.437208           1.0   \n",
       "3     0.927861  1.0  0.780807  ...  0.221511      0.413216           1.0   \n",
       "4     0.993426  1.0  0.767176  ...  0.219992      0.391755           1.0   \n",
       "...        ...  ...       ...  ...       ...           ...           ...   \n",
       "1418  0.961976  1.0  0.820065  ...  0.267391      0.409244           1.0   \n",
       "1419  0.944208  1.0  0.820065  ...  0.268392      0.426828           1.0   \n",
       "1420  0.950249  1.0  0.820065  ...  0.263709      0.393910           1.0   \n",
       "1421  0.948827  1.0  0.820065  ...  0.267171      0.388909           1.0   \n",
       "1422  0.926439  1.0  0.820065  ...  0.270371      0.399323           1.0   \n",
       "\n",
       "      class_prob_1  class_prob_4  class_prob_5  class_prob_6  class_prob_7  \\\n",
       "0         0.100000      0.005556      0.727778           0.0      0.166667   \n",
       "1         0.038889      0.000000      0.833333           0.0      0.127778   \n",
       "2         0.172222      0.000000      0.761111           0.0      0.066667   \n",
       "3         0.116667      0.005556      0.800000           0.0      0.077778   \n",
       "4         0.050000      0.000000      0.883333           0.0      0.066667   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1418      0.200000      0.000000      0.800000           0.0      0.000000   \n",
       "1419      0.294444      0.000000      0.705556           0.0      0.000000   \n",
       "1420      0.211111      0.000000      0.788889           0.0      0.000000   \n",
       "1421      0.155556      0.000000      0.838889           0.0      0.005556   \n",
       "1422      0.200000      0.005556      0.794444           0.0      0.000000   \n",
       "\n",
       "      observed_class  predicted_class  \n",
       "0                  5                5  \n",
       "1                  5                5  \n",
       "2                  5                5  \n",
       "3                  5                5  \n",
       "4                  5                5  \n",
       "...              ...              ...  \n",
       "1418               5                5  \n",
       "1419               5                5  \n",
       "1420               5                5  \n",
       "1421               5                5  \n",
       "1422               5                5  \n",
       "\n",
       "[1423 rows x 40 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec57741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee99ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B09</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast1</th>\n",
       "      <th>contrast2</th>\n",
       "      <th>correlation1</th>\n",
       "      <th>correlation2</th>\n",
       "      <th>dissimilarity1</th>\n",
       "      <th>dissimilarity2</th>\n",
       "      <th>energy1</th>\n",
       "      <th>energy2</th>\n",
       "      <th>homogeneity1</th>\n",
       "      <th>homogeneity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182252</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>0.088483</td>\n",
       "      <td>0.067632</td>\n",
       "      <td>0.260882</td>\n",
       "      <td>0.549615</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.607676</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>0.620502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199727</td>\n",
       "      <td>0.349690</td>\n",
       "      <td>0.281767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199181</td>\n",
       "      <td>0.050298</td>\n",
       "      <td>0.197563</td>\n",
       "      <td>0.348391</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182252</td>\n",
       "      <td>0.058277</td>\n",
       "      <td>0.090824</td>\n",
       "      <td>0.072169</td>\n",
       "      <td>0.260882</td>\n",
       "      <td>0.549615</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.579780</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>0.620502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>0.328553</td>\n",
       "      <td>0.284199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182518</td>\n",
       "      <td>0.049952</td>\n",
       "      <td>0.199563</td>\n",
       "      <td>0.327212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182252</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>0.092463</td>\n",
       "      <td>0.066768</td>\n",
       "      <td>0.255294</td>\n",
       "      <td>0.545385</td>\n",
       "      <td>0.625722</td>\n",
       "      <td>0.591862</td>\n",
       "      <td>0.687544</td>\n",
       "      <td>0.620502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200993</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.280697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200448</td>\n",
       "      <td>0.050458</td>\n",
       "      <td>0.196698</td>\n",
       "      <td>0.349971</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182252</td>\n",
       "      <td>0.058277</td>\n",
       "      <td>0.107912</td>\n",
       "      <td>0.076059</td>\n",
       "      <td>0.260882</td>\n",
       "      <td>0.549615</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>0.620502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196611</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>0.282156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196063</td>\n",
       "      <td>0.050241</td>\n",
       "      <td>0.197880</td>\n",
       "      <td>0.344484</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182252</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.109785</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>0.260882</td>\n",
       "      <td>0.549615</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.655117</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>0.620502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179764</td>\n",
       "      <td>0.324259</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179205</td>\n",
       "      <td>0.049881</td>\n",
       "      <td>0.199960</td>\n",
       "      <td>0.322909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.072202</td>\n",
       "      <td>0.104401</td>\n",
       "      <td>0.104149</td>\n",
       "      <td>0.321176</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.979076</td>\n",
       "      <td>0.961976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249781</td>\n",
       "      <td>0.409207</td>\n",
       "      <td>0.365149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250341</td>\n",
       "      <td>0.039020</td>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.409244</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.060340</td>\n",
       "      <td>0.101592</td>\n",
       "      <td>0.103717</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.806538</td>\n",
       "      <td>0.975469</td>\n",
       "      <td>0.944208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266530</td>\n",
       "      <td>0.427971</td>\n",
       "      <td>0.366316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266030</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.268392</td>\n",
       "      <td>0.426828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0.117978</td>\n",
       "      <td>0.105445</td>\n",
       "      <td>0.335882</td>\n",
       "      <td>0.812692</td>\n",
       "      <td>0.981602</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236050</td>\n",
       "      <td>0.393421</td>\n",
       "      <td>0.360868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.236991</td>\n",
       "      <td>0.039552</td>\n",
       "      <td>0.263709</td>\n",
       "      <td>0.393910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.111891</td>\n",
       "      <td>0.104149</td>\n",
       "      <td>0.330588</td>\n",
       "      <td>0.812692</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.948827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232058</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.364857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232703</td>\n",
       "      <td>0.039069</td>\n",
       "      <td>0.267171</td>\n",
       "      <td>0.388909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>0.110019</td>\n",
       "      <td>0.105877</td>\n",
       "      <td>0.327059</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.926439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.399624</td>\n",
       "      <td>0.368554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.241668</td>\n",
       "      <td>0.038618</td>\n",
       "      <td>0.270371</td>\n",
       "      <td>0.399323</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           B01       B02       B03       B04       B05       B06       B07  \\\n",
       "0     0.182252  0.054409  0.088483  0.067632  0.260882  0.549615  0.628247   \n",
       "1     0.182252  0.058277  0.090824  0.072169  0.260882  0.549615  0.628247   \n",
       "2     0.182252  0.054409  0.092463  0.066768  0.255294  0.545385  0.625722   \n",
       "3     0.182252  0.058277  0.107912  0.076059  0.260882  0.549615  0.628247   \n",
       "4     0.182252  0.063950  0.109785  0.082757  0.260882  0.549615  0.628247   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4732  0.259542  0.072202  0.104401  0.104149  0.321176  0.806923  0.979076   \n",
       "4733  0.259542  0.060340  0.101592  0.103717  0.320000  0.806538  0.975469   \n",
       "4734  0.259542  0.061372  0.117978  0.105445  0.335882  0.812692  0.981602   \n",
       "4735  0.259542  0.063950  0.111891  0.104149  0.330588  0.812692  0.977273   \n",
       "4736  0.259542  0.075297  0.110019  0.105877  0.327059  0.806923  0.977273   \n",
       "\n",
       "           B08       B8A       B09  ...  contrast1  contrast2  correlation1  \\\n",
       "0     0.607676  0.699432  0.620502  ...   0.199727   0.349690      0.281767   \n",
       "1     0.579780  0.699432  0.620502  ...   0.183075   0.328553      0.284199   \n",
       "2     0.591862  0.687544  0.620502  ...   0.200993   0.351267      0.280697   \n",
       "3     0.626155  0.699432  0.620502  ...   0.196611   0.345791      0.282156   \n",
       "4     0.655117  0.699432  0.620502  ...   0.179764   0.324259      0.284686   \n",
       "...        ...       ...       ...  ...        ...        ...           ...   \n",
       "4732  0.961976  1.000000  0.820065  ...   0.249781   0.409207      0.365149   \n",
       "4733  0.944208  1.000000  0.820065  ...   0.266530   0.427971      0.366316   \n",
       "4734  0.950249  1.000000  0.820065  ...   0.236050   0.393421      0.360868   \n",
       "4735  0.948827  1.000000  0.820065  ...   0.232058   0.388759      0.364857   \n",
       "4736  0.926439  1.000000  0.820065  ...   0.241406   0.399624      0.368554   \n",
       "\n",
       "      correlation2  dissimilarity1  dissimilarity2   energy1   energy2  \\\n",
       "0              0.0             1.0        0.199181  0.050298  0.197563   \n",
       "1              0.0             1.0        0.182518  0.049952  0.199563   \n",
       "2              0.0             1.0        0.200448  0.050458  0.196698   \n",
       "3              0.0             1.0        0.196063  0.050241  0.197880   \n",
       "4              0.0             1.0        0.179205  0.049881  0.199960   \n",
       "...            ...             ...             ...       ...       ...   \n",
       "4732           0.0             1.0        0.250341  0.039020  0.267391   \n",
       "4733           0.0             1.0        0.266030  0.038885  0.268392   \n",
       "4734           0.0             1.0        0.236991  0.039552  0.263709   \n",
       "4735           0.0             1.0        0.232703  0.039069  0.267171   \n",
       "4736           0.0             1.0        0.241668  0.038618  0.270371   \n",
       "\n",
       "      homogeneity1  homogeneity2  \n",
       "0         0.348391           1.0  \n",
       "1         0.327212           1.0  \n",
       "2         0.349971           1.0  \n",
       "3         0.344484           1.0  \n",
       "4         0.322909           1.0  \n",
       "...            ...           ...  \n",
       "4732      0.409244           1.0  \n",
       "4733      0.426828           1.0  \n",
       "4734      0.393910           1.0  \n",
       "4735      0.388909           1.0  \n",
       "4736      0.399323           1.0  \n",
       "\n",
       "[1451 rows x 33 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model['X test data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa019b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model['model'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97736e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [f'class_prob_{name}' for name in trained_model['model'].classes_]\n",
    "probs_df=pd.DataFrame(trained_model['y proba'], columns=col_names)\n",
    "probs_df['observed_class']=trained_model['y test data'].reset_index(drop=True)\n",
    "probs_df['predicted_class']=trained_model['y predicted']\n",
    "all_df= pd.concat([trained_model['X test data'].reset_index(drop=True), probs_df], axis=1)\n",
    "\n",
    "all_df.to_csv(f'conformal_predictions_{model}_{core}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48796f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5558247693940066"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_df['observed_class'], all_df['predicted_class'], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2761613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForest'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388204c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5bf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6f2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24231e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa99f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04da76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94548756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7\n",
       "1       7\n",
       "2       7\n",
       "3       7\n",
       "4       7\n",
       "       ..\n",
       "4732    5\n",
       "4733    5\n",
       "4734    5\n",
       "4735    5\n",
       "4736    5\n",
       "Name: class, Length: 1451, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model['y test data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14199e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360492da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ee5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86025b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65edba1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
